{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, random, os, json, spacy, seaborn, requests, string, copy\n",
    "import pandas as pd\n",
    "import pyterrier as pt \n",
    "from autocorrect import Speller\n",
    "from pyterrier.measures import *\n",
    "from pathlib import *\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#### learning to rank\n",
    "import fastrank\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#### setting(jupyter notebook)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#### setting(pandas)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSynonymsByGoogle(query):\n",
    "    url = \"https://www.google.com/search?q=\" + query\n",
    "    res = requests.get(url) \n",
    "    Soup = BeautifulSoup(res.text,'html.parser') \n",
    "    links = Soup.findAll('a')\n",
    "    link_img = None\n",
    "    for link in links:\n",
    "        if 'Images' in link.get_text():\n",
    "            link_img = link.get('href')\n",
    "            break\n",
    "    synonyms = []\n",
    "    if link_img:\n",
    "        url = 'https://www.google.com'+link_img\n",
    "        res = requests.get(url)\n",
    "        Soup = BeautifulSoup(res.text,'html.parser') \n",
    "        span_synonyms = Soup.find_all(\"a\",class_= \"TwVfHd\")\n",
    "        for span in span_synonyms:\n",
    "            synonyms.append(span.get_text('innerText'))\n",
    "    return synonyms\n",
    "\n",
    "def isVerb(text):\n",
    "    \"\"\"Check if is verb.\"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return doc[0].pos_ == 'VERB'\n",
    "\n",
    "def RemoveOneChar(s):\n",
    "    idx_rm = random.randint(0,len(s)-1)\n",
    "    return s[:idx_rm]+s[idx_rm+1:]\n",
    "\n",
    "def InsertOneChar(s):\n",
    "    char = random.choice(string.ascii_uppercase)\n",
    "    idx_insert = random.randint(0,len(s)-1)\n",
    "    return s[:idx_rm]+char+s[idx_rm:]\n",
    "\n",
    "def replaceOneChar(s):\n",
    "    char = random.choice(string.ascii_uppercase)\n",
    "    idx_insert = random.randint(0,len(s)-1)\n",
    "    return s[:idx_rm]+char+s[idx_rm+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    def __init__(self,pt):\n",
    "        self.pt = pt    \n",
    "        self.setPaths()\n",
    "        self.spell = Speller()\n",
    "        ## spell('temwork') => teamwork\n",
    "        \n",
    "    def splitDataSet(self):\n",
    "        RANK_CUTOFF = 10\n",
    "        SEED=42\n",
    "        self.train_topics, self.test_topics = train_test_split(self.df_query, test_size=4, random_state=SEED)\n",
    "\n",
    "        \n",
    "    def setPaths(self): \n",
    "        self.paths = dict()\n",
    "        self.paths['dataset'] = os.path.join(Path(os.getcwd()).parent.absolute(),'dataset')\n",
    "        self.paths['data_txt']  = os.path.join(self.paths['dataset'], 'data_txt')\n",
    "        self.paths['data_json'] = os.path.join(self.paths['dataset'], 'data_json')\n",
    "        self.paths['data_csv']  = os.path.join(self.paths['dataset'], 'pyterrier-index.csv')\n",
    "        self.paths['pt_index']  = './resume_index'\n",
    "        self.paths['synonymDict']  = '../dataset/query_expansion.pkl'\n",
    "        self.paths['query']  = '../dataset/query.csv'\n",
    "        self.paths['qrels']  = '../dataset/qrel/'\n",
    "        \n",
    "    def JsontoDataFrame(self, profiles_json, split=True):\n",
    "        rows = []\n",
    "        docno = 0\n",
    "        for profile in profiles_json:\n",
    "            meta_data = {\n",
    "                \"education\": json.dumps(profile[\"Education\"]),\n",
    "                \"company\": None,\n",
    "                \"title\": None,\n",
    "                \"period\": None,\n",
    "            }\n",
    "            for expBlock in profile[\"Experience\"]:\n",
    "                meta_data[\"company\"] = expBlock[\"company\"]\n",
    "                meta_data[\"title\"]   = expBlock[\"title\"]\n",
    "                meta_data[\"period\"]  = expBlock[\"period\"]\n",
    "                if expBlock[\"description\"]:\n",
    "                    bulletpoints = expBlock[\"description\"].split('\\n') if split else [expBlock[\"description\"]]\n",
    "                    for bulletpoint in bulletpoints:\n",
    "                        if len(bulletpoint.split()) >= 5:\n",
    "                            row = [str(docno),bulletpoint]\n",
    "                            for item in meta_data.values():\n",
    "                                row.append(item)\n",
    "                            rows.append(row)\n",
    "                            docno += 1\n",
    "        docs_df =   pd.DataFrame(rows,columns= ['docno','text']+list(meta_data.keys()) )\n",
    "        return docs_df\n",
    "\n",
    "    def loadDocs(self, verbose=False):\n",
    "        if verbose:\n",
    "            print('----------------load profiles(documents) to profiles----------------')\n",
    "        \n",
    "        if not os.path.exists(self.paths['data_csv']):\n",
    "            # get raw json files & preprocess\n",
    "            profiles_json = []\n",
    "            for filename in os.listdir(self.paths['data_json']):\n",
    "                path_profile  = os.path.join( self.paths['data_json'], filename  )\n",
    "                with open(path_profile) as ptr:\n",
    "                    profile_json = json.load(ptr)\n",
    "                    profiles_json.append(profile_json)\n",
    "            profiles = self.JsontoDataFrame(profiles_json)\n",
    "\n",
    "        else:\n",
    "            profiles = pd.read_csv(self.paths['data_csv'])\n",
    "            profiles['docno'] = profiles['docno'].astype(str)\n",
    "            profiles['company'] =  profiles['company'].astype(str)\n",
    "        self.profiles = profiles\n",
    "    \n",
    "    def loadQueries(self, misspell = False, autoCorrect = False, expand = True, verbose=False):\n",
    "        \"\"\"Load queries.\"\"\"\n",
    "        if verbose:\n",
    "            print('----------------load queries to df_query----------------')\n",
    "            \n",
    "        df_query = pd.read_csv(self.paths['query'])\n",
    "        df_query['qid'] = df_query['qid'].astype(str)\n",
    "        self.df_query = df_query\n",
    "        \n",
    "        if misspell:\n",
    "            self.makeMisspelling(numReplace = 0, numRemove = 0, numInsert = 1, verbose=verbose)\n",
    "            \n",
    "        if autoCorrect:\n",
    "            self.autoCorrectQueris(verbose=verbose)\n",
    "            \n",
    "        if expand:\n",
    "            self.expandQuery(verbose=verbose)\n",
    "        \n",
    "    def loadQrels(self, verbose=False):\n",
    "        \"\"\"Load labeled 7 queries.\"\"\"\n",
    "        if verbose:\n",
    "            print('----------------load queries & labels to qrels----------------')\n",
    "            \n",
    "        queries = []\n",
    "        for i in range(1, 15):\n",
    "            subpath = self.paths['qrels'] + f'query - {i}.csv'\n",
    "            if verbose:\n",
    "                print('load the labels for query - %d'%(i),subpath)\n",
    "            df = pd.read_csv(subpath)\n",
    "            queries.append(df)\n",
    "        qrels = pd.concat(queries)\n",
    "\n",
    "        qrels = qrels.rename(columns={\"score\": \"label\"})\n",
    "\n",
    "        qrels = qrels.drop(['education', 'company', 'title', 'period', 'text'], axis=1)\n",
    "        qrels = qrels.reset_index(drop=True)\n",
    "        qrels = qrels.fillna(-1)\n",
    "\n",
    "        qrels['qid'] = qrels['qid'].astype(str)\n",
    "        qrels['docno'] = qrels['docno'].astype(str)\n",
    "        qrels['label'] = qrels['label'].astype(int)\n",
    "        self.qrels = qrels\n",
    "    \n",
    "    def expandQuery(self,verbose=False):\n",
    "        \"\"\"Expand Query with specific weights.\"\"\"\n",
    "        if verbose:\n",
    "            print('----------------expand the queries by appending synonyms----------------')\n",
    "        \n",
    "        for ind in self.df_query.index:\n",
    "            query_tmp = self.df_query['query'][ind]\n",
    "            synonyms = getSynonymsByGoogle(query_tmp)\n",
    "            query_expand = [query_tmp]*(len(synonyms)*2) + synonyms\n",
    "            self.df_query['query'][ind] = ' '.join(query_expand)\n",
    "            if verbose:\n",
    "                print(query_tmp,synonyms)\n",
    "    \n",
    "    def makeMisspelling(self, numReplace=1, numRemove = 1, numInsert = 1,verbose=False):\n",
    "        \"\"\"Reload Query and randomly insert & remove chars\"\"\"\n",
    "        if verbose:\n",
    "            print('----------------generate misspelling by randomly insert&remove char from original queries----------------')\n",
    "        for ind in self.df_query.index:\n",
    "            query_tmp = self.df_query['query'][ind]\n",
    "            query_misspelling = query_tmp\n",
    "            \n",
    "            numRemove = min(numRemove,len(query_misspelling)-1)\n",
    "            for ite in range(numReplace):\n",
    "                query_misspelling = replaceOneChar(query_misspelling)\n",
    "            for ite in range(numRemove):\n",
    "                query_misspelling = RemoveOneChar(query_misspelling)\n",
    "            for ite in range(numInsert):\n",
    "                query_misspelling = InsertOneChar(query_misspelling)\n",
    "            \n",
    "                \n",
    "            self.df_query['query'][ind] = query_misspelling\n",
    "            if verbose:\n",
    "                print(query_tmp,' => ',query_misspelling)\n",
    "    \n",
    "    def autoCorrectQueris(self,verbose=False):\n",
    "        if verbose:\n",
    "            print('----------------Autocorrection----------------')\n",
    "            \n",
    "        for ind in self.df_query.index:\n",
    "            query_tmp = self.df_query['query'][ind]\n",
    "            query_tmp2 = query_tmp.split()\n",
    "            query_autoCorrect = ' '.join([self.spell(query) for query in query_tmp2])\n",
    "            self.df_query['query'][ind] = query_autoCorrect\n",
    "            if verbose:\n",
    "                print(query_tmp, ' => ' ,query_autoCorrect)\n",
    "                \n",
    "    def indexing(self, verbose=False):\n",
    "        if verbose:\n",
    "            print('----------------index the profiles(documents)----------------')\n",
    "            \n",
    "        ### load index fils to index obj\n",
    "        ### If index fils are not existed, create index files by indexer\n",
    "        #if not os.path.exists(paths['pt_index'] + \"/data.properties\"):\n",
    "        if True:\n",
    "            index_dir = self.paths['pt_index']\n",
    "            indexer = self.pt.DFIndexer(index_dir, overwrite=True)\n",
    "            index_ref = indexer.index(self.profiles[\"text\"], self.profiles[\"docno\"], self.profiles[\"education\"], self.profiles[\"title\"], self.profiles[\"company\"], self.profiles[\"period\"], self.profiles[\"text\"])\n",
    "            #index_ref = indexer.index(profiles[\"text\"], profiles[\"docno\"])\n",
    "\n",
    "            ### load the index\n",
    "            index = self.pt.IndexFactory.of(index_ref)\n",
    "        else:\n",
    "            index = self.pt.IndexFactory.of(paths['pt_index'])\n",
    "        \n",
    "        if verbose:\n",
    "            ### show the stat \n",
    "            print(index.getCollectionStatistics().toString())\n",
    "   \n",
    "        self.index = index\n",
    "        \n",
    "    def loadIRmodels(self,modelNames = ['TF_IDF','BM25','DPH'], verbose = False):\n",
    "        if verbose:\n",
    "            print('----------------load IR models (default: TF_IDF, BM25, DPH)----------------')\n",
    "        self.models = {  modelName: self.pt.BatchRetrieve(self.index, wmodel=modelName) for modelName in modelNames}\n",
    "    \n",
    "    def learning_to_rank(self):\n",
    "        RANK_CUTOFF = 20\n",
    "        SEED = 10\n",
    "        bm25 = self.models['BM25']\n",
    "        pt   = self.pt\n",
    "        index = self.index\n",
    "        \n",
    "        ltr_feats2 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(index, [\"text\",\"title\", \"education\", \"company\", \"period\"]) >> (\n",
    "                            pt.transformer.IdentityTransformer()\n",
    "                            ** \n",
    "                            (pt.apply.query(lambda row: 'test') >> bm25)\n",
    "                            )\n",
    "        fnames=[\"isVerb\"]\n",
    "        \n",
    "        ### random forest pipe\n",
    "        rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=8)\n",
    "        rf_pipe2 = ltr_feats2 >> pt.ltr.apply_learned_model(rf)\n",
    "        %time rf_pipe2.fit(self.df_query, self.qrels)\n",
    "        self.models['Random_Forest'] = rf_pipe2\n",
    "        \n",
    "    def search(self,query,modelName):\n",
    "        if modelName not in self.models.keys():\n",
    "            print('Model not found, Available:',list(self.models.keys()))\n",
    "        else:\n",
    "            return self.models[modelName].search(query)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up ResumeHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------load profiles(documents) to profiles----------------\n",
      "----------------load queries to df_query----------------\n",
      "----------------load queries & labels to qrels----------------\n",
      "load the labels for query - 1 ../dataset/qrel/query - 1.csv\n",
      "load the labels for query - 2 ../dataset/qrel/query - 2.csv\n",
      "load the labels for query - 3 ../dataset/qrel/query - 3.csv\n",
      "load the labels for query - 4 ../dataset/qrel/query - 4.csv\n",
      "load the labels for query - 5 ../dataset/qrel/query - 5.csv\n",
      "load the labels for query - 6 ../dataset/qrel/query - 6.csv\n",
      "load the labels for query - 7 ../dataset/qrel/query - 7.csv\n",
      "----------------index the profiles(documents)----------------\n",
      "Number of documents: 363\n",
      "Number of terms: 1510\n",
      "Number of postings: 4637\n",
      "Number of fields: 0\n",
      "Number of tokens: 4906\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n",
      "----------------load IR models (default: TF_IDF, BM25, DPH)----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Information retrieval nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>teamwork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>web front end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>aws cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>data visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>sdk platform build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>data analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>kubernetes container</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>rest api request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>quality integrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>site-reliability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>object-oriented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>design pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>data learning model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>web security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>distributed infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>system design latency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>architecture system design quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                               query\n",
       "0   1   sql                               \n",
       "1   2   Information retrieval nlp         \n",
       "2   3   teamwork                          \n",
       "3   4   web front end                     \n",
       "4   5   aws cloud                         \n",
       "5   6   machine learning                  \n",
       "6   7   data visualization                \n",
       "7   8   sdk platform build                \n",
       "8   9   data analytics                    \n",
       "9   10  kubernetes container              \n",
       "10  11  rest api request                  \n",
       "11  12  quality integrity                 \n",
       "12  13  site-reliability                  \n",
       "13  14  object-oriented                   \n",
       "14  15  design pattern                    \n",
       "15  16  data learning model               \n",
       "16  17  web security                      \n",
       "17  18  distributed infrastructure        \n",
       "18  19  system design latency             \n",
       "19  20  architecture system design quality"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()\n",
    "ResumeHelper = SearchEngine(pt)\n",
    "ResumeHelper.loadDocs(verbose= True)\n",
    "ResumeHelper.loadQueries(misspell=False,autoCorrect=False,expand=False, verbose= True)\n",
    "ResumeHelper.loadQrels(verbose= True)\n",
    "ResumeHelper.indexing(verbose= True)\n",
    "ResumeHelper.loadIRmodels(verbose= True)\n",
    "ResumeHelper.df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------load queries to df_query----------------\n",
      "----------------generate misspelling by randomly insert&remove char from original queries----------------\n",
      "sql  =>  sqlY\n",
      "Information retrieval nlp  =>  InfoQrmation retrieval nlp\n",
      "teamwork  =>  teamVwork\n",
      "web front end  =>  web Gfront end\n",
      "aws cloud  =>  aws Xcloud\n",
      "machine learning  =>  machXine learning\n",
      "data visualization  =>  dataN visualization\n",
      "sdk platform build  =>  sdk Rplatform build\n",
      "data analytics  =>  dataP analytics\n",
      "kubernetes container  =>  kubeUrnetes container\n",
      "rest api request  =>  restL api request\n",
      "quality integrity  =>  qualZity integrity\n",
      "site-reliability  =>  siteG-reliability\n",
      "object-oriented  =>  objeHct-oriented\n",
      "design pattern  =>  desiZgn pattern\n",
      "data learning model  =>  dataC learning model\n",
      "web security  =>  web Tsecurity\n",
      "distributed infrastructure  =>  distAributed infrastructure\n",
      "system design latency  =>  systYem design latency\n",
      "architecture system design quality  =>  archRitecture system design quality\n",
      "----------------Autocorrection----------------\n",
      "sqlY  =>  sql\n",
      "InfoQrmation retrieval nlp  =>  Information retrieval nl\n",
      "teamVwork  =>  teamwork\n",
      "web Gfront end  =>  web Front end\n",
      "aws Xcloud  =>  aws Cloud\n",
      "machXine learning  =>  machine learning\n",
      "dataN visualization  =>  data visualization\n",
      "sdk Rplatform build  =>  sdk Platform build\n",
      "dataP analytics  =>  data analytics\n",
      "kubeUrnetes container  =>  kubeUrnetes container\n",
      "restL api request  =>  rest api request\n",
      "qualZity integrity  =>  quality integrity\n",
      "siteG-reliability  =>  site-reliability\n",
      "objeHct-oriented  =>  object-oriented\n",
      "desiZgn pattern  =>  design pattern\n",
      "dataC learning model  =>  data learning model\n",
      "web Tsecurity  =>  web Security\n",
      "distAributed infrastructure  =>  distributed infrastructure\n",
      "systYem design latency  =>  system design latency\n",
      "archRitecture system design quality  =>  architecture system design quality\n"
     ]
    }
   ],
   "source": [
    "ResumeHelper.loadQueries(misspell=True,autoCorrect=True,expand=False, verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo the usage of ResumeHelper (You can skip this block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: sql\n",
      "IR model: DPH\n",
      "\n",
      "Top10 relevent documents:\n",
      "91    • Analyzed clients’ requirements, designed ER models and constructed corresponding databases using SQL server including 200k records; gathered comprehensive profiles of cars and customers by SQL queries\n",
      "96    • Accelerated data processing by 50% by automating data retrieval and extraction with SQL queries\n",
      "152    • Wrote stored procedures, functions, and packages using PL/SQL, reducing project time by 25%\n",
      "216    • Cooperated with engineers and PMs to design image recommendation feature; analyzed relationship between image usage and ad performance using TB level data (SQL, C#)\n",
      "243    •Designed an automated customer retention system with Python and SQL to complete weekly client status report for strategy development. Increased customer retention rate by 15%.\n",
      "176    - Use SQL / python to combine various source of financial data\n",
      "347    - Implement front-end and back-end for various projects with multiple programming languages and platforms, including ASP.NET, MVC, React.js, Node.js, JavaScript, C#, SQL, and Python\n",
      "114    • Developed an automated system by designing APIs with Python, SQL, and Shell Script to facilitate other engineers’ model training processes, such as filtering, processing, and auto‑labeling data from the internal shared database\n",
      "55    ● As teaching assistant reviewed student's real-world application projects and presentation gave some feedbacks/suggestions and trained student's R, python, SQL though TA sessions. Also, developed and maintained technique questions bank.\n",
      "189    The curriculum includes Linux, SQL, Java, Python, Javascript, Data Analysis, Machine Learning, Data Visualization. In the final project, we leveraged the skills above and build an online platform to evaluate reasonable house prices of certain area and provide analytic report and visualization.\n"
     ]
    }
   ],
   "source": [
    "docids = ResumeHelper.search(query = 'sql', modelName='DPH')['docid'][:10]\n",
    "print('Query: sql')\n",
    "print('IR model: DPH')\n",
    "print()\n",
    "print('Top10 relevent documents:')\n",
    "for rank,docid in enumerate(docids):\n",
    "    doc = ResumeHelper.profiles.loc[ResumeHelper.profiles['docno'] == str(docid)]['text'].to_string()\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp (w/o query expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 297 ms, total: 1.67 s\n",
      "Wall time: 882 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF_IDF</td>\n",
       "      <td>0.383435</td>\n",
       "      <td>0.718270</td>\n",
       "      <td>0.672158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.383491</td>\n",
       "      <td>0.718270</td>\n",
       "      <td>0.672158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.400839</td>\n",
       "      <td>0.765254</td>\n",
       "      <td>0.698722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.366590</td>\n",
       "      <td>0.762776</td>\n",
       "      <td>0.730332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map    nDCG@5   nDCG@10\n",
       "0  TF_IDF         0.383435  0.718270  0.672158\n",
       "1  BM25           0.383491  0.718270  0.672158\n",
       "2  DPH            0.400839  0.765254  0.698722\n",
       "3  Random_Forest  0.366590  0.762776  0.730332"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original queries\n",
    "ResumeHelper.loadQueries(misspell=False, autoCorrect=False, expand=False, verbose= False)\n",
    "\n",
    "# Train RF with origianl queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp (with query expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 314 ms, total: 1.32 s\n",
      "Wall time: 924 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF_IDF</td>\n",
       "      <td>0.494266</td>\n",
       "      <td>0.768400</td>\n",
       "      <td>0.771243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.496571</td>\n",
       "      <td>0.768400</td>\n",
       "      <td>0.771243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.506957</td>\n",
       "      <td>0.806511</td>\n",
       "      <td>0.797315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.482390</td>\n",
       "      <td>0.985868</td>\n",
       "      <td>0.940411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map    nDCG@5   nDCG@10\n",
       "0  TF_IDF         0.494266  0.768400  0.771243\n",
       "1  BM25           0.496571  0.768400  0.771243\n",
       "2  DPH            0.506957  0.806511  0.797315\n",
       "3  Random_Forest  0.482390  0.985868  0.940411"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original queries => query expansion\n",
    "ResumeHelper.loadQueries(misspell=False, autoCorrect=False, expand=True, verbose= False)\n",
    "\n",
    "# Train RF with augmented queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 664 ms, sys: 234 ms, total: 898 ms\n",
      "Wall time: 651 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF_IDF</td>\n",
       "      <td>0.309748</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.601278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.309748</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.601278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.327497</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.632336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.298993</td>\n",
       "      <td>0.740909</td>\n",
       "      <td>0.668672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map    nDCG@5   nDCG@10\n",
       "0  TF_IDF         0.309748  0.682605  0.601278\n",
       "1  BM25           0.309748  0.682605  0.601278\n",
       "2  DPH            0.327497  0.740909  0.632336\n",
       "3  Random_Forest  0.298993  0.740909  0.668672"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original queries => query expansion\n",
    "ResumeHelper.loadQueries(misspell=True, autoCorrect=False, expand=False, verbose= False)\n",
    "\n",
    "# Train RF with augmented queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 746 ms, sys: 282 ms, total: 1.03 s\n",
      "Wall time: 792 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF_IDF</td>\n",
       "      <td>0.365688</td>\n",
       "      <td>0.644799</td>\n",
       "      <td>0.616955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.365744</td>\n",
       "      <td>0.644799</td>\n",
       "      <td>0.616955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.382320</td>\n",
       "      <td>0.701326</td>\n",
       "      <td>0.650689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.348325</td>\n",
       "      <td>0.698849</td>\n",
       "      <td>0.682299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map    nDCG@5   nDCG@10\n",
       "0  TF_IDF         0.365688  0.644799  0.616955\n",
       "1  BM25           0.365744  0.644799  0.616955\n",
       "2  DPH            0.382320  0.701326  0.650689\n",
       "3  Random_Forest  0.348325  0.698849  0.682299"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original queries => query expansion\n",
    "ResumeHelper.loadQueries(misspell=True, autoCorrect=True, expand=False, verbose= False)\n",
    "\n",
    "# Train RF with augmented queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 936 ms, sys: 335 ms, total: 1.27 s\n",
      "Wall time: 924 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF_IDF</td>\n",
       "      <td>0.453224</td>\n",
       "      <td>0.694930</td>\n",
       "      <td>0.723961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.455761</td>\n",
       "      <td>0.694930</td>\n",
       "      <td>0.723961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.470159</td>\n",
       "      <td>0.748980</td>\n",
       "      <td>0.762009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.953788</td>\n",
       "      <td>0.901664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       map    nDCG@5   nDCG@10\n",
       "0  TF_IDF         0.453224  0.694930  0.723961\n",
       "1  BM25           0.455761  0.694930  0.723961\n",
       "2  DPH            0.470159  0.748980  0.762009\n",
       "3  Random_Forest  0.445887  0.953788  0.901664"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the original queries => query expansion\n",
    "ResumeHelper.loadQueries(misspell=True, autoCorrect=True, expand=True, verbose= False)\n",
    "\n",
    "# Train RF with augmented queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original queries => query expansion\n",
    "ResumeHelper.loadQueries(misspell=True, autoCorrect=True, expand=False, verbose= False)\n",
    "\n",
    "# Train RF with augmented queries\n",
    "ResumeHelper.learning_to_rank()\n",
    "\n",
    "# Run exp.\n",
    "ResumeHelper.pt.Experiment(\n",
    "    retr_systems = [ResumeHelper.models['TF_IDF'],ResumeHelper.models['BM25'],ResumeHelper.models['DPH'],ResumeHelper.models['Random_Forest']],\n",
    "    topics = ResumeHelper.df_query.loc[1:7],\n",
    "    qrels = ResumeHelper.qrels,\n",
    "    names = ['TF_IDF','BM25','DPH','Random_Forest'],\n",
    "    eval_metrics=[\"map\", NDCG@5 ,NDCG@10] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
